{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"code.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"cells":[{"cell_type":"code","metadata":{"id":"kDjzpTOzxnyR","colab_type":"code","outputId":"baaa5d7e-c750-4cb7-f51a-064a92ffaf79","executionInfo":{"status":"ok","timestamp":1573470381323,"user_tz":-330,"elapsed":32003,"user":{"displayName":"Amit Tiwari","photoUrl":"","userId":"07201453663632754060"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0UCUei8-2aPf","colab_type":"code","outputId":"fc1ebc5e-fd33-468a-d967-5573e8b1161a","executionInfo":{"status":"ok","timestamp":1573470391160,"user_tz":-330,"elapsed":5533,"user":{"displayName":"Amit Tiwari","photoUrl":"","userId":"07201453663632754060"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!ls \"gdrive/My Drive/tweet_generator\""],"execution_count":5,"outputs":[{"output_type":"stream","text":["code  summary\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hf4b16KopBx7","outputId":"0aabc997-97ca-4f34-f2d1-c611a62440c8","executionInfo":{"status":"ok","timestamp":1573470409396,"user_tz":-330,"elapsed":13884,"user":{"displayName":"Amit Tiwari","photoUrl":"","userId":"07201453663632754060"}},"colab":{"base_uri":"https://localhost:8080/","height":541}},"source":["!pip install gensim\n","!pip install wget\n","  \n","import nltk\n","nltk.download('punkt')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.4)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.3.1)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.17.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n","Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.10.7)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.9.11)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.7 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.13.7)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.1)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.7->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.7->boto3->smart-open>=1.2.1->gensim) (2.6.1)\n","Collecting wget\n","  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=b462e81ec195e673b0883c65ba0818bb3d6edee4c89ac97c3db9c834081e7c1c\n","  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lA1tCj2mn_2x","colab":{}},"source":["from nltk.tokenize import word_tokenize\n","import re\n","import collections\n","import pickle\n","import numpy as np\n","from gensim.models.keyedvectors import KeyedVectors\n","from gensim.test.utils import get_tmpfile\n","from gensim.scripts.glove2word2vec import glove2word2vec\n","\n","default_path = \"gdrive/My Drive/tweet_generator/summary/\"\n","\n","train_article_path = default_path + \"sumdata/train/train_news_sports.txt\"\n","train_title_path   = default_path + \"sumdata/train/train_tweets_sports.txt\"\n","valid_article_path = default_path + \"sumdata/train/test_news_sports.txt\"\n","valid_title_path   = default_path + \"sumdata/train/test_tweets_sports.txt\"\n","\n","\n","\n","def clean_str(sentence):\n","    sentence = re.sub(\"[#.]+\", \"#\", sentence)\n","    return sentence\n","\n","\n","def get_text_list(data_path, toy):\n","    with open (data_path, \"r\", encoding=\"utf-8\") as f:\n","        if not toy:\n","            return [clean_str(x.strip()) for x in f.readlines()][:]\n","        else:\n","            return [clean_str(x.strip()) for x in f.readlines()][:50]\n","\n","\n","def build_dict(step, word_dict_folder_path, toy=False):\n","    if step == \"train\":\n","        train_article_list = get_text_list(train_article_path, toy)\n","        train_title_list = get_text_list(train_title_path, toy)\n","\n","        words = list()\n","        for sentence in train_article_list + train_title_list:\n","            for word in word_tokenize(sentence):\n","                words.append(word)\n","\n","        word_counter = collections.Counter(words).most_common()\n","        word_dict = dict()\n","        word_dict[\"<padding>\"] = 0\n","        word_dict[\"<unk>\"] = 1\n","        word_dict[\"<s>\"] = 2\n","        word_dict[\"</s>\"] = 3\n","        for word, _ in word_counter:\n","            word_dict[word] = len(word_dict)\n","\n","        with open(word_dict_folder_path + \"word_dict.pickle\", \"wb\") as f:\n","            pickle.dump(word_dict, f)\n","\n","    elif step == \"valid\":\n","        with open(word_dict_folder_path + \"word_dict.pickle\", \"rb\") as f:\n","            word_dict = pickle.load(f)\n","\n","    reversed_dict = dict(zip(word_dict.values(), word_dict.keys()))\n","\n","    article_max_len = 50\n","    summary_max_len = 15\n","\n","    return word_dict, reversed_dict, article_max_len, summary_max_len\n","\n","\n","def build_dataset(step, word_dict, article_max_len, summary_max_len, toy=False):\n","    if step == \"train\":\n","        article_list = get_text_list(train_article_path, toy)\n","        title_list = get_text_list(train_title_path, toy)\n","    elif step == \"valid\":\n","        article_list = get_text_list(valid_article_path, toy)\n","    else:\n","        raise NotImplementedError\n","\n","    x = [word_tokenize(d) for d in article_list]\n","    x = [[word_dict.get(w, word_dict[\"<unk>\"]) for w in d] for d in x]\n","    x = [d[:article_max_len] for d in x]\n","    x = [d + (article_max_len - len(d)) * [word_dict[\"<padding>\"]] for d in x]\n","    \n","    if step == \"valid\":\n","        return x\n","    else:        \n","        y = [word_tokenize(d) for d in title_list]\n","        y = [[word_dict.get(w, word_dict[\"<unk>\"]) for w in d] for d in y]\n","        y = [d[:(summary_max_len - 1)] for d in y]\n","        return x, y\n","\n","\n","def batch_iter(inputs, outputs, batch_size, num_epochs):\n","    inputs = np.array(inputs)\n","    outputs = np.array(outputs)\n","\n","    num_batches_per_epoch = (len(inputs) - 1) // batch_size + 1\n","    for epoch in range(num_epochs):\n","        for batch_num in range(num_batches_per_epoch):\n","            start_index = batch_num * batch_size\n","            end_index = min((batch_num + 1) * batch_size, len(inputs))\n","            yield inputs[start_index:end_index], outputs[start_index:end_index]\n","\n","\n","def get_init_embedding(reversed_dict, embedding_size):\n","    print(\"Loading Glove vectors...\")\n","\n","    with open( default_path + \"glove/model_glove_300.pkl\", 'rb') as handle:\n","        word_vectors = pickle.load(handle)\n","        \n","    word_vec_list = list()\n","    for _, word in sorted(reversed_dict.items()):\n","        try:\n","            word_vec = word_vectors.word_vec(word)\n","        except KeyError:\n","            word_vec = np.zeros([embedding_size], dtype=np.float32)\n","\n","        word_vec_list.append(word_vec)\n","\n","    # Assign random vector to <s>, </s> token\n","    word_vec_list[2] = np.random.normal(0, 1, embedding_size)\n","    word_vec_list[3] = np.random.normal(0, 1, embedding_size)\n","\n","    return np.array(word_vec_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LigU33gP1HRs","colab_type":"code","colab":{}},"source":["# with open(d)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KzQHorNtOuFY","colab_type":"code","colab":{}},"source":["# with open(default_path+\"sumdata/train/test_one.txt\",\"w\") as inp:\n","#   inp.write(\"Bengaluru The Congress in Karnataka has termed the Supreme Court order on the political crisis in the state as bad judgment which seemed to protect the defectors and encourage horse trading In a series of tweets Karnataka Pradesh Congress Committee KPCC president Dinesh Gundu Rao termed it an extraordinary order On Wednesday the Supreme Court directed that the 15 rebel Congress and JD S MLAs ought not to be compelled to take part in the proceedings of the state Assembly where Chief Minister HD Kumaraswamy is slated to face the floor test on July 18 Supreme Court order seems perfectly coordinated to help the rebel MLAs to violate the whip It has set a wrong precedent as the value of the Whip as per 10th schedule of the Constitution is now redundant An extraordinary order indeed Rao tweeted The SupremeCourt verdict is now encroaching upon the rights of the Legislature This is a bad judgement which seems to protect the defectors and encourages horse trading and also violating the doctrine of separation of powers KarnatakaPoliticalCrisis Dinesh Gundu Rao ದ ನ ಶ ಗ ಡ ರ ವ dineshgrao July 17 2019 The SupremeCourt verdict is now encroaching upon the rights of the Legislature This is a bad judgement which seems to protect the defectors and encourages horse trading and also violating the doctrine of separation of powers he said in another tweet A bench headed by Chief Justice Ranjan Gogoi also said the speaker was free to decide on the resignations of the rebel MLAs within the time frame decided by him The apex court was hearing the plea of 15 rebel Congress JD S MLAs seeking direction for the speaker to accept their resignations from the assembly Noting that Congress disqualification petition with the speaker against party MLAs is as per section 2 1a of the anti defection law Rao tweeted It s not for violating the whip but for indulging in anti party activities to join hands with BJP to topple our govt and voluntarily giving up membership The Congress has moved disqualification petition against 13 MLAs including independent R Shankar who had merged his Karnataka Pragnyavantha Janatha Party KPJP with it The other Congress MLAs include Pratap Gowda Patil BC Patil Shivram Hebbar S T Somashekar Byrati Basavaraj Anand Singh Roshan Baig Munirathna K Sudhakar and MTB Nagaraj Disqualification petition had been moved against Ramesh Jarkiholi and Mahesh Kumatalli earlier itself The JD S too on its part had moved disqualification petition against its 3 MLAs Gopalaiah A H Vishwanath and Narayana Gowda but the speaker had said it was not in proper format and those who submitted were not party MLAs or senior leaders As many as 16 MLAs 13 from the Congress and three from the JD S have resigned while two independent MLAs S Shankar and H Nagesh have withdrawn their support to the coalition government keeping it on the edge Get the best of News18 delivered to your inbox subscribe to News18 Daybreak Follow News18 com on Twitter Instagram Facebook Telegram TikTok and on YouTube and stay in the know with what s happening in the world around you in real time\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKuuwXaEOyD1","colab_type":"code","colab":{}},"source":["# with open(default_path+\"sumdata/train/test_title_one.txt\",\"w\") as inp:\n","#   inp.write(\"The Court hearing the plea of 15 rebel Cong JD S MLAs seeking direction for the speaker to accept their resignations said the Speaker was free to decide on the resignations of the rebel MLAs within the time frame decided by him https t co znxBaVUFQG\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GKHwTTZg5eJa","colab":{}},"source":["import tensorflow as tf\n","from tensorflow.contrib import rnn\n","\n","\n","class Model(object):\n","    def __init__(self, reversed_dict, article_max_len, summary_max_len, args, forward_only=False):\n","        self.vocabulary_size = len(reversed_dict)\n","        self.embedding_size = args.embedding_size\n","        self.num_hidden = args.num_hidden\n","        self.num_layers = args.num_layers\n","        self.learning_rate = args.learning_rate\n","        self.beam_width = args.beam_width\n","        if not forward_only:\n","            self.keep_prob = args.keep_prob\n","        else:\n","            self.keep_prob = 1.0\n","        self.cell = tf.nn.rnn_cell.BasicLSTMCell\n","        with tf.variable_scope(\"decoder/projection\"):\n","            self.projection_layer = tf.layers.Dense(self.vocabulary_size, use_bias=False)\n","\n","        self.batch_size = tf.placeholder(tf.int32, (), name=\"batch_size\")\n","        self.X = tf.placeholder(tf.int32, [None, article_max_len])\n","        self.X_len = tf.placeholder(tf.int32, [None])\n","        self.decoder_input = tf.placeholder(tf.int32, [None, summary_max_len])\n","        self.decoder_len = tf.placeholder(tf.int32, [None])\n","        self.decoder_target = tf.placeholder(tf.int32, [None, summary_max_len])\n","        self.global_step = tf.Variable(0, trainable=False)\n","\n","        with tf.name_scope(\"embedding\"):\n","            if not forward_only and args.glove:\n","                init_embeddings = tf.constant(get_init_embedding(reversed_dict, self.embedding_size), dtype=tf.float32)\n","            else:\n","                init_embeddings = tf.random_uniform([self.vocabulary_size, self.embedding_size], -1.0, 1.0)\n","            self.embeddings = tf.get_variable(\"embeddings\", initializer=init_embeddings)\n","            self.encoder_emb_inp = tf.transpose(tf.nn.embedding_lookup(self.embeddings, self.X), perm=[1, 0, 2])\n","            self.decoder_emb_inp = tf.transpose(tf.nn.embedding_lookup(self.embeddings, self.decoder_input), perm=[1, 0, 2])\n","\n","        with tf.name_scope(\"encoder\"):\n","            fw_cells = [self.cell(self.num_hidden) for _ in range(self.num_layers)]\n","            bw_cells = [self.cell(self.num_hidden) for _ in range(self.num_layers)]\n","            fw_cells = [rnn.DropoutWrapper(cell) for cell in fw_cells]\n","            bw_cells = [rnn.DropoutWrapper(cell) for cell in bw_cells]\n","\n","            encoder_outputs, encoder_state_fw, encoder_state_bw = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(\n","                fw_cells, bw_cells, self.encoder_emb_inp,\n","                sequence_length=self.X_len, time_major=True, dtype=tf.float32)\n","            self.encoder_output = tf.concat(encoder_outputs, 2)\n","            encoder_state_c = tf.concat((encoder_state_fw[0].c, encoder_state_bw[0].c), 1)\n","            encoder_state_h = tf.concat((encoder_state_fw[0].h, encoder_state_bw[0].h), 1)\n","            self.encoder_state = rnn.LSTMStateTuple(c=encoder_state_c, h=encoder_state_h)\n","\n","        with tf.name_scope(\"decoder\"), tf.variable_scope(\"decoder\") as decoder_scope:\n","            decoder_cell = self.cell(self.num_hidden * 2)\n","\n","            if not forward_only:\n","                attention_states = tf.transpose(self.encoder_output, [1, 0, 2])\n","                attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n","                    self.num_hidden * 2, attention_states, memory_sequence_length=self.X_len, normalize=True)\n","                decoder_cell = tf.contrib.seq2seq.AttentionWrapper(decoder_cell, attention_mechanism,\n","                                                                   attention_layer_size=self.num_hidden * 2)\n","                initial_state = decoder_cell.zero_state(dtype=tf.float32, batch_size=self.batch_size)\n","                initial_state = initial_state.clone(cell_state=self.encoder_state)\n","                helper = tf.contrib.seq2seq.TrainingHelper(self.decoder_emb_inp, self.decoder_len, time_major=True)\n","                decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, helper, initial_state)\n","                outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, output_time_major=True, scope=decoder_scope)\n","                self.decoder_output = outputs.rnn_output\n","                self.logits = tf.transpose(\n","                    self.projection_layer(self.decoder_output), perm=[1, 0, 2])\n","                self.logits_reshape = tf.concat(\n","                    [self.logits, tf.zeros([self.batch_size, summary_max_len - tf.shape(self.logits)[1], self.vocabulary_size])], axis=1)\n","            else:\n","                tiled_encoder_output = tf.contrib.seq2seq.tile_batch(\n","                    tf.transpose(self.encoder_output, perm=[1, 0, 2]), multiplier=self.beam_width)\n","                tiled_encoder_final_state = tf.contrib.seq2seq.tile_batch(self.encoder_state, multiplier=self.beam_width)\n","                tiled_seq_len = tf.contrib.seq2seq.tile_batch(self.X_len, multiplier=self.beam_width)\n","                attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n","                    self.num_hidden * 2, tiled_encoder_output, memory_sequence_length=tiled_seq_len, normalize=True)\n","                decoder_cell = tf.contrib.seq2seq.AttentionWrapper(decoder_cell, attention_mechanism,\n","                                                                   attention_layer_size=self.num_hidden * 2)\n","                initial_state = decoder_cell.zero_state(dtype=tf.float32, batch_size=self.batch_size * self.beam_width)\n","                initial_state = initial_state.clone(cell_state=tiled_encoder_final_state)\n","                decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n","                    cell=decoder_cell,\n","                    embedding=self.embeddings,\n","                    start_tokens=tf.fill([self.batch_size], tf.constant(2)),\n","                    end_token=tf.constant(3),\n","                    initial_state=initial_state,\n","                    beam_width=self.beam_width,\n","                    output_layer=self.projection_layer\n","                )\n","                outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n","                    decoder, output_time_major=True, maximum_iterations=summary_max_len, scope=decoder_scope)\n","                self.prediction = tf.transpose(outputs.predicted_ids, perm=[1, 2, 0])\n","\n","        with tf.name_scope(\"loss\"):\n","            if not forward_only:\n","                crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n","                    logits=self.logits_reshape, labels=self.decoder_target)\n","                weights = tf.sequence_mask(self.decoder_len, summary_max_len, dtype=tf.float32)\n","                self.loss = tf.reduce_sum(crossent * weights / tf.to_float(self.batch_size))\n","\n","                params = tf.trainable_variables()\n","                gradients = tf.gradients(self.loss, params)\n","                clipped_gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\n","                optimizer = tf.train.AdamOptimizer(self.learning_rate)\n","                self.update = optimizer.apply_gradients(zip(clipped_gradients, params), global_step=self.global_step)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QeBcsZO_zk9Z","colab_type":"text"},"source":["## Model specification"]},{"cell_type":"code","metadata":{"id":"2fDJEg3W0cl8","colab_type":"code","colab":{}},"source":["model_name = \"sports_model\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8fYdUf6Wzrj3","colab_type":"code","colab":{}},"source":["model_folder_path = default_path + \"saved_models/\" + model_name + \"/\"\n","word_dict_folder_path = default_path + \"word_dicts/\" + model_name + \"/\"\n","results_folder_path =  default_path + \"results/\" + model_name + \"/\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mNo7e0fMziNr","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"x_xON6b4nS8x"},"source":["## Train"]},{"cell_type":"code","metadata":{"id":"f2isenlwqNl7","colab_type":"code","colab":{}},"source":["import time\n","start = time.perf_counter()\n","import tensorflow as tf\n","import argparse\n","import pickle\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zhcU4hXUZKI","colab_type":"code","outputId":"f40f2624-e081-491c-be57-9854c4df678f","executionInfo":{"status":"ok","timestamp":1573477569810,"user_tz":-330,"elapsed":1375,"user":{"displayName":"Amit Tiwari","photoUrl":"","userId":"07201453663632754060"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["if not os.path.exists(model_folder_path):\n","    os.makedirs(model_folder_path)\n","    print(model_name + \" model directory created\")"],"execution_count":43,"outputs":[{"output_type":"stream","text":["sports_model model directory created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZxgZMmVo04QW","colab_type":"code","outputId":"fa30fdbe-3027-4c08-c952-05b5595b751c","executionInfo":{"status":"ok","timestamp":1573477571053,"user_tz":-330,"elapsed":625,"user":{"displayName":"Amit Tiwari","photoUrl":"","userId":"07201453663632754060"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["if not os.path.exists(word_dict_folder_path):\n","    os.makedirs(word_dict_folder_path)\n","    print(model_name + \" word_dict directory created\")"],"execution_count":44,"outputs":[{"output_type":"stream","text":["sports_model word_dict directory created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vq9ZA0hFnUZJ","outputId":"4cf39196-b807-408b-bbe2-f565afa9de3b","executionInfo":{"status":"ok","timestamp":1573481176912,"user_tz":-330,"elapsed":3604275,"user":{"displayName":"Amit Tiwari","photoUrl":"","userId":"07201453663632754060"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["class args:\n","    pass\n","  \n","args.num_hidden=150\n","args.num_layers=2\n","args.beam_width=10\n","args.glove=\"store_true\"\n","args.embedding_size=300\n","\n","args.learning_rate=1e-3\n","args.batch_size=64\n","args.num_epochs=50\n","args.keep_prob = 0.8\n","\n","args.toy=False\n","\n","args.with_model=\"store_true\"\n","\n","args.continue_with_prev_model = False\n","\n","\n","\n","\n","\n","if args.with_model:\n","    if os.path.exists(model_folder_path + 'checkpoint'):\n","        old_model_checkpoint_path = open(model_folder_path + 'checkpoint', 'r')\n","        old_model_checkpoint_path = \"\".join([model_folder_path,old_model_checkpoint_path.read().splitlines()[0].split('\"')[1] ])\n","        args.continue_with_prev_model = True\n","        print(\"old checkpoint restored\")\n","\n","\n","print(\"Building dictionary...\")\n","word_dict, reversed_dict, article_max_len, summary_max_len = build_dict(\"train\", word_dict_folder_path,args.toy)\n","print(\"Loading training dataset...\")\n","train_x, train_y = build_dataset(\"train\", word_dict, article_max_len, summary_max_len, args.toy)\n","\n","tf.reset_default_graph()\n","\n","with tf.Session() as sess:\n","    model = Model(reversed_dict, article_max_len, summary_max_len, args)\n","    sess.run(tf.global_variables_initializer())\n","    saver = tf.train.Saver(tf.global_variables(), max_to_keep=2)\n","    if args.continue_with_prev_model:\n","        print(\"Continuing from previous trained model:\" , old_model_checkpoint_path , \"...\")\n","        saver.restore(sess, old_model_checkpoint_path )\n","\n","    batches = batch_iter(train_x, train_y, args.batch_size, args.num_epochs)\n","    num_batches_per_epoch = (len(train_x) - 1) // args.batch_size + 1\n","\n","    print(\"\\nIteration starts.\")\n","    print(\"Number of batches per epoch :\", num_batches_per_epoch)\n","    for batch_x, batch_y in batches:\n","        batch_x_len = list(map(lambda x: len([y for y in x if y != 0]), batch_x))\n","        batch_decoder_input = list(map(lambda x: [word_dict[\"<s>\"]] + list(x), batch_y))\n","        batch_decoder_len = list(map(lambda x: len([y for y in x if y != 0]), batch_decoder_input))\n","        batch_decoder_output = list(map(lambda x: list(x) + [word_dict[\"</s>\"]], batch_y))\n","\n","        batch_decoder_input = list(\n","            map(lambda d: d + (summary_max_len - len(d)) * [word_dict[\"<padding>\"]], batch_decoder_input))\n","        batch_decoder_output = list(\n","            map(lambda d: d + (summary_max_len - len(d)) * [word_dict[\"<padding>\"]], batch_decoder_output))\n","\n","        train_feed_dict = {\n","            model.batch_size: len(batch_x),\n","            model.X: batch_x,\n","            model.X_len: batch_x_len,\n","            model.decoder_input: batch_decoder_input,\n","            model.decoder_len: batch_decoder_len,\n","            model.decoder_target: batch_decoder_output\n","        }\n","\n","        _, step, loss = sess.run([model.update, model.global_step, model.loss], feed_dict=train_feed_dict)\n","\n","        if step % 1000 == 0:\n","            print(\"step {0}: loss = {1}\".format(step, loss))\n","\n","        if step % num_batches_per_epoch == 0:\n","            hours, rem = divmod(time.perf_counter() - start, 3600)\n","            minutes, seconds = divmod(rem, 60)\n","            saver.save(sess, model_folder_path + \"model.ckpt\", global_step=step)\n","            print(\" Epoch {0}: Model is saved.\".format(step // num_batches_per_epoch),\n","            \"Elapsed: {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds) , \"\\n\")"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Building dictionary...\n","Loading training dataset...\n","Loading Glove vectors...\n","\n","Iteration starts.\n","Number of batches per epoch : 157\n"," Epoch 1: Model is saved. Elapsed: 00:02:05.33 \n","\n"," Epoch 2: Model is saved. Elapsed: 00:03:16.41 \n","\n"," Epoch 3: Model is saved. Elapsed: 00:04:26.08 \n","\n"," Epoch 4: Model is saved. Elapsed: 00:05:36.00 \n","\n"," Epoch 5: Model is saved. Elapsed: 00:06:46.62 \n","\n"," Epoch 6: Model is saved. Elapsed: 00:07:56.41 \n","\n","step 1000: loss = 64.16128540039062\n"," Epoch 7: Model is saved. Elapsed: 00:09:07.18 \n","\n"," Epoch 8: Model is saved. Elapsed: 00:10:17.10 \n","\n"," Epoch 9: Model is saved. Elapsed: 00:11:26.93 \n","\n"," Epoch 10: Model is saved. Elapsed: 00:12:36.54 \n","\n"," Epoch 11: Model is saved. Elapsed: 00:13:46.73 \n","\n"," Epoch 12: Model is saved. Elapsed: 00:14:57.66 \n","\n","step 2000: loss = 40.052677154541016\n"," Epoch 13: Model is saved. Elapsed: 00:16:07.59 \n","\n"," Epoch 14: Model is saved. Elapsed: 00:17:17.43 \n","\n"," Epoch 15: Model is saved. Elapsed: 00:18:27.55 \n","\n"," Epoch 16: Model is saved. Elapsed: 00:19:37.78 \n","\n"," Epoch 17: Model is saved. Elapsed: 00:20:49.15 \n","\n"," Epoch 18: Model is saved. Elapsed: 00:22:00.49 \n","\n"," Epoch 19: Model is saved. Elapsed: 00:23:12.70 \n","\n","step 3000: loss = 29.478403091430664\n"," Epoch 20: Model is saved. Elapsed: 00:24:24.10 \n","\n"," Epoch 21: Model is saved. Elapsed: 00:25:35.18 \n","\n"," Epoch 22: Model is saved. Elapsed: 00:26:46.38 \n","\n"," Epoch 23: Model is saved. Elapsed: 00:27:57.34 \n","\n"," Epoch 24: Model is saved. Elapsed: 00:29:09.18 \n","\n"," Epoch 25: Model is saved. Elapsed: 00:30:20.21 \n","\n","step 4000: loss = 18.02768325805664\n"," Epoch 26: Model is saved. Elapsed: 00:31:31.69 \n","\n"," Epoch 27: Model is saved. Elapsed: 00:32:42.62 \n","\n"," Epoch 28: Model is saved. Elapsed: 00:33:53.93 \n","\n"," Epoch 29: Model is saved. Elapsed: 00:35:04.62 \n","\n"," Epoch 30: Model is saved. Elapsed: 00:36:15.20 \n","\n"," Epoch 31: Model is saved. Elapsed: 00:37:27.48 \n","\n","step 5000: loss = 13.100862503051758\n"," Epoch 32: Model is saved. Elapsed: 00:38:38.60 \n","\n"," Epoch 33: Model is saved. Elapsed: 00:39:49.86 \n","\n"," Epoch 34: Model is saved. Elapsed: 00:41:01.61 \n","\n"," Epoch 35: Model is saved. Elapsed: 00:42:13.35 \n","\n"," Epoch 36: Model is saved. Elapsed: 00:43:26.01 \n","\n"," Epoch 37: Model is saved. Elapsed: 00:44:37.70 \n","\n"," Epoch 38: Model is saved. Elapsed: 00:45:50.51 \n","\n","step 6000: loss = 9.462640762329102\n"," Epoch 39: Model is saved. Elapsed: 00:47:02.11 \n","\n"," Epoch 40: Model is saved. Elapsed: 00:48:13.28 \n","\n"," Epoch 41: Model is saved. Elapsed: 00:49:24.41 \n","\n"," Epoch 42: Model is saved. Elapsed: 00:50:35.38 \n","\n"," Epoch 43: Model is saved. Elapsed: 00:51:46.69 \n","\n"," Epoch 44: Model is saved. Elapsed: 00:52:58.38 \n","\n","step 7000: loss = 6.074134349822998\n"," Epoch 45: Model is saved. Elapsed: 00:54:10.14 \n","\n"," Epoch 46: Model is saved. Elapsed: 00:55:21.35 \n","\n"," Epoch 47: Model is saved. Elapsed: 00:56:32.54 \n","\n"," Epoch 48: Model is saved. Elapsed: 00:57:43.91 \n","\n"," Epoch 49: Model is saved. Elapsed: 00:58:55.02 \n","\n"," Epoch 50: Model is saved. Elapsed: 01:00:06.31 \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TbbtwLe7njGS"},"source":["## Test"]},{"cell_type":"code","metadata":{"id":"pj1X-exd7oww","colab_type":"code","outputId":"bfb9eb7b-0203-4171-ca7b-740e43544335","executionInfo":{"status":"ok","timestamp":1573481212356,"user_tz":-330,"elapsed":1224,"user":{"displayName":"Amit Tiwari","photoUrl":"","userId":"07201453663632754060"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["if not os.path.exists(results_folder_path):\n","    os.makedirs(results_folder_path)\n","    print(model_name + \" result directory created\")"],"execution_count":46,"outputs":[{"output_type":"stream","text":["sports_model result directory created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1IUJ0dpon1Hi","outputId":"e819a6bf-fcfc-4b11-fdae-4f769eb0d6e8","executionInfo":{"status":"ok","timestamp":1573481240375,"user_tz":-330,"elapsed":26066,"user":{"displayName":"Amit Tiwari","photoUrl":"","userId":"07201453663632754060"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["import tensorflow as tf\n","import pickle\n","\n","\n","tf.reset_default_graph()\n","\n","class args:\n","    pass\n","  \n","args.num_hidden=150\n","args.num_layers=2\n","args.beam_width=10\n","args.glove=\"store_true\"\n","args.embedding_size=300\n","\n","args.learning_rate=1e-3\n","args.batch_size=64\n","args.num_epochs=10\n","args.keep_prob = 0.8\n","\n","args.toy=False\n","\n","args.with_model=\"store_true\"\n","\n","\n","\n","print(\"Loading dictionary...\")\n","word_dict, reversed_dict, article_max_len, summary_max_len = build_dict(\"valid\", word_dict_folder_path, args.toy)\n","print(\"Loading validation dataset...\")\n","valid_x = build_dataset(\"valid\", word_dict, article_max_len, summary_max_len, args.toy)\n","valid_x_len = [len([y for y in x if y != 0]) for x in valid_x]\n","print(\"Loading article and reference...\")\n","article = get_text_list(valid_article_path, args.toy)\n","reference = get_text_list(valid_title_path, args.toy)\n","\n","with tf.Session() as sess:\n","    print(\"Loading saved model...\")\n","    model = Model(reversed_dict, article_max_len, summary_max_len, args, forward_only=True)\n","    saver = tf.train.Saver(tf.global_variables())\n","    ckpt = tf.train.get_checkpoint_state(model_folder_path)\n","    saver.restore(sess, ckpt.model_checkpoint_path)\n","\n","    batches = batch_iter(valid_x, [0] * len(valid_x), args.batch_size, 1)\n","\n","    print(\"Writing summaries to 'result.txt'...\")\n","    summary_array = []\n","    for batch_x, _ in batches:\n","        batch_x_len = [len([y for y in x if y != 0]) for x in batch_x]\n","\n","        valid_feed_dict = {\n","            model.batch_size: len(batch_x),\n","            model.X: batch_x,\n","            model.X_len: batch_x_len,\n","        }\n","\n","        prediction = sess.run(model.prediction, feed_dict=valid_feed_dict)\n","        prediction_output = [[reversed_dict[y] for y in x] for x in prediction[:, 0, :]]\n","        for line in prediction_output:\n","            summary = list()\n","            for word in line:\n","                if word == \"</s>\":\n","                    break\n","                if word not in summary:\n","                    summary.append(word)\n","            summary_array.append(\" \".join(summary))\n","        \n","        with open(results_folder_path + \"result.txt\", \"w\") as f:\n","            for line in summary_array:\n","                print(line,file=f)\n","\n","    print('Summaries have been generated')"],"execution_count":47,"outputs":[{"output_type":"stream","text":["Loading dictionary...\n","Loading validation dataset...\n","Loading article and reference...\n","Loading saved model...\n","INFO:tensorflow:Restoring parameters from gdrive/My Drive/tweet_generator/summary/saved_models/sports_model/model.ckpt-7850\n","Writing summaries to 'result.txt'...\n","Summaries have been generated\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FvnBdHIpb-wo","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qdyXj5w32uGr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}